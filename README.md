# Money-Laundering Prevention

## Problem Statement

The Money-Laundering Prevention project aims to detect potential money laundering activities in financial transactions. The dataset contains information about various financial transactions, including details about the sender, receiver, amounts, currencies, and payment formats.

This is a Multi-Class Classification problem, where the classes represent different categories of transactions: legitimate transactions, suspicious transactions, and potentially fraudulent transactions.

## Solution Proposed

In this project, the focus is on developing a machine learning model to identify patterns and behaviors that might lead to money laundering. By analyzing historical transaction data, the system aims to classify transactions into one of three categories: legitimate, suspicious, or potentially fraudulent. This approach allows for the identification of unusual and potentially illicit financial activities.

The objective is to enhance the anti-money laundering efforts and minimize false predictions to reduce the cost and effort related to unnecessary investigations. The proposed solution aims to provide financial institutions with a tool to better prioritize and target their money laundering prevention efforts.


## Tech Stack Used

The Money-Laundering Prevention project leverages a combination of programming languages, libraries, and tools to build an effective solution for detecting potential money laundering activities. The following tech stack was employed:

 * Python: The primary programming language used for data preprocessing, modeling, and analysis.
 * Pandas: A versatile data manipulation library in Python for data loading, cleaning, and transformation.
 * NumPy: A fundamental package for numerical computations in Python.
 * Scikit*learn: A machine learning library for various algorithms, including classification and model evaluation.
 * FastAPI: A modern, fast web framework for building APIs with Python 3.7+ based on standard Python type hints.
 * Dill: A serializer for Python objects used for saving and loading model objects.
 * AWS (Amazon Web Services): Cloud storage and computing platform used for storing datasets and trained models (optional if not used).
 * Git: Version control system for tracking code changes and collaborating with team members.
 * Jupyter Notebook: Interactive environment used for exploratory data analysis and experimentation.
 * Logging: Utilized for tracking events and debugging during the pipeline execution.
 * YAML: Used for configuration file management, enabling easy parameter tuning.

## Infrastructure Required.

 * AWS S3
 * AWS EC2
 * AWS ECR
 * Git Actions
 * Terraform

## How to run?

 Before running the project, ensure that you have an AWS account for accessing services like S3, ECR, and EC2 instances.


## Data Collection

The dataset used in this project is the [Elliptic Dataset](https://www.kaggle.com/datasets/ellipticco/elliptic-data-set)
, which provides a comprehensive view of Bitcoin transactions and their associated entities. This dataset offers valuable insights into the world of cryptocurrency transactions and serves as the foundation for detecting potentially illicit activities.

## Dataset Overview

Focus on Bitcoin Transactions: The Elliptic Dataset centers around transactions within the Bitcoin network, capturing information about sender-receiver relationships, transaction amounts, currencies, and more.

 * Categorization of Entities: Transactions are categorized into two distinct groups:

    * Licit Entities: These include legitimate actors such as exchanges, wallet providers, and miners.
    * Illicit Entities: This category encompasses entities associated with scams, malware, terrorism, ransomware, and other illicit activities.
    * Licit vs. Illicit Transactions: Each transaction is labeled based on the nature of the initiating entity. Transactions generated by licit entities are labeled as licit, while those associated with illicit entities are labeled as illicit.

 * Key Dataset Characteristics

    Graph Network: The dataset is structured as a graph network of Bitcoin transactions. Nodes represent individual transactions, while directed edges denote payment flows.

 * Feature-Rich: Each transaction node is accompanied by 166 features. These features are crafted using publicly available information and offer insights into various transaction aspects.

 * Temporal Information: Transactions are associated with specific time steps, representing when they were confirmed. The dataset spans 49 distinct timesteps, each separated by a 2-week interval.

 * Class Imbalance: The dataset exhibits a class imbalance, with only a small percentage (2%) of illicit transactions and a larger percentage (21%) of licit transactions. This distribution influences the model training process.

 * Aggregated Features: Among the features, 72 are aggregated, summarizing transaction information and providing context about correlations among neighboring transactions.

 * Research and Practical Significance
The Elliptic Dataset holds significant importance for various applications:

 * Money Laundering Detection: The dataset's focus on illicit activities makes it a crucial tool for developing models to identify potential money laundering transactions.

 * Fraud Prevention: By analyzing transaction patterns, the dataset can aid in building fraud detection systems to safeguard financial ecosystems.

 * Cryptocurrency Analysis: Researchers can gain insights into cryptocurrency behavior, trends, and the relationships between different entities.

 * Machine Learning Experimentation: Data scientists can leverage the dataset to create, train, and evaluate machine learning models for binary classification tasks.

 * Availability

The dataset is available on Kaggle, offering researchers and data enthusiasts the opportunity to explore, analyze, and contribute to the ongoing efforts to prevent money laundering and enhance the security of financial transactions within the cryptocurrency landscape.


## Project Archietecture

![image](https://user-images.githubusercontent.com/57321948/193536768-ae704adc-32d9-4c6c-b234-79c152f756c5.png)

## Deployment Archietecture

![image](https://user-images.githubusercontent.com/57321948/193536973-4530fe7d-5509-4609-bfd2-cd702fc82423.png)

### Step 1: Clone the repository

```bash
git clone https://github.com/SuyodhanJ6/Money-Laundering-Prevention.git
```

### Step 2- Create a conda environment after opening the repository

```bash
conda create -n venv python=3.7.6 -y
```

```bash
conda activate venv
```

### Step 3 - Install the requirements

```bash
pip install -r requirements.txt
```

### Step 4 - Export the environment variable

```bash
export AWS_ACCESS_KEY_ID=<AWS_ACCESS_KEY_ID>

export AWS_SECRET_ACCESS_KEY=<AWS_SECRET_ACCESS_KEY>

export AWS_DEFAULT_REGION=<AWS_DEFAULT_REGION>

```

### Step 5 - Run the application server

```bash
python app.py
```

### Step 6. Train application

```bash
http://localhost:8080/train

```

### Step 7. Prediction application

```bash
http://localhost:8080/predict

```

## Run locally

1. Check if the Dockerfile is available in the project directory

2. Build the Docker image

```
docker build -t money . 

```

3. Run the Docker image

```
docker run -d -e AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}" -e AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}" -e AWS_DEFAULT_REGION="${{ secrets.AWS_DEFAULT_REGION }}" -p 8080:8080 money
```


